{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50d5afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Full Oracle Dataset...\n",
      "‚ú® Features detected (6): ['Age', 'Sex_Code', 'Race_Code', 'local_snap_claim_rate', 'Education_Code', 'Employment_Status']\n",
      "‚úÖ Data loaded. Training size: 120578\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Methodological Exploration: Comparative Analysis of Poverty Classifiers\n",
    "# In this notebook, we evaluate how different algorithm families (Linear, Tree-based, Neural, and Bayesian) \n",
    "# model the complex socio-demographic and economic boundaries of poverty using the full \"Oracle\" dataset.\n",
    "\n",
    "# %%\n",
    "# 1. SETUP & DATA LOADING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"üìÇ Loading Full Oracle Dataset...\")\n",
    "\n",
    "DATA_PROCESSED = os.path.join(\"..\", \"data\", \"processed\")\n",
    "oracle_path = os.path.join(DATA_PROCESSED, \"df_person_oracle.csv\")\n",
    "\n",
    "if not os.path.exists(oracle_path):\n",
    "    raise FileNotFoundError(\"‚ùå Oracle dataset missing. Run the Oracle generation step in the pipeline.\")\n",
    "\n",
    "df = pd.read_csv(oracle_path, dtype={'PUMA': str})\n",
    "\n",
    "# Define Target and Weights\n",
    "target = 'is_poor'\n",
    "weights = 'Person_Weight'\n",
    "\n",
    "# Auto-detect all features (excluding metadata/targets)\n",
    "exclude_cols = [target, weights, 'PUMA', 'POVPIP'] \n",
    "features = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"‚ú® Features detected ({len(features)}): {features}\")\n",
    "\n",
    "# Separate continuous vs categorical for the preprocessing pipeline\n",
    "# (Age, Hours_Worked, and SNAP rates are continuous. Everything else is categorical)\n",
    "continuous_candidates = ['Age', 'local_snap_claim_rate', 'Hours_Worked']\n",
    "numeric_features = [c for c in continuous_candidates if c in features]\n",
    "categorical_features = [c for c in features if c not in numeric_features]\n",
    "\n",
    "# Cast categoricals to string so sklearn handles them strictly as categories\n",
    "for c in categorical_features:\n",
    "    df[c] = df[c].astype(str)\n",
    "\n",
    "# Split the data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "w = df[weights]\n",
    "\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaded. Training size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb20dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç≥ Preparing Preprocessing Pipelines...\n",
      "MODEL                     | AUC SCORE  | BRIER (CALIB)\n",
      "-------------------------------------------------------\n",
      "Logistic Regression       | 0.7619     | 0.2207\n",
      "Random Forest             | 0.7722     | 0.2033\n",
      "Neural Network (MLP)      | 0.7758     | 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine    | 0.7460     | 0.0825\n",
      "LightGBM                  | 0.7852     | 0.1920\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 2. THE MEGA BAKE-OFF\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "print(\"üç≥ Preparing Preprocessing Pipelines...\")\n",
    "\n",
    "# Standardize inputs for fairness across model families\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model zoo\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ]),\n",
    "    \n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    \n",
    "    \"Neural Network (MLP)\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        # 2 hidden layers, early stopping to prevent over-fitting\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=500, early_stopping=True, random_state=42))\n",
    "    ]),\n",
    "    \n",
    "    \"Support Vector Machine\": Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        # LinearSVC wrapped in a calibrator to get Probabilities for AUC\n",
    "        ('classifier', CalibratedClassifierCV(LinearSVC(class_weight='balanced', max_iter=2000, random_state=42), cv=3))\n",
    "    ]),\n",
    "    \n",
    "    \"LightGBM\": lgb.LGBMClassifier(\n",
    "        objective='binary', \n",
    "        metric='auc',\n",
    "        is_unbalance=True, \n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"{'MODEL':<25} | {'AUC SCORE':<10} | {'BRIER (CALIB)':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # LightGBM handles categories natively (bypasses the Pipeline)\n",
    "    if name == \"LightGBM\":\n",
    "        X_train_c = X_train.copy()\n",
    "        X_test_c = X_test.copy()\n",
    "        for c in categorical_features:\n",
    "            X_train_c[c] = X_train_c[c].astype('category')\n",
    "            X_test_c[c] = X_test_c[c].astype('category')\n",
    "        model.fit(X_train_c, y_train, sample_weight=w_train)\n",
    "        preds = model.predict_proba(X_test_c)[:, 1]\n",
    "    \n",
    "    # Sklearn models use the strict pipeline\n",
    "    else:\n",
    "        # MLP does not support sample_weight in scikit-learn\n",
    "        if name == \"Neural Network (MLP)\":\n",
    "            model.fit(X_train, y_train) \n",
    "        else:\n",
    "            # Pass sample weights to the classifier step for the others\n",
    "            model.fit(X_train, y_train, classifier__sample_weight=w_train)\n",
    "            \n",
    "        preds = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "    # We still EVALUATE all models using the weights, so the test is fair\n",
    "    auc = roc_auc_score(y_test, preds, sample_weight=w_test)\n",
    "    brier = brier_score_loss(y_test, preds, sample_weight=w_test)\n",
    "    \n",
    "    results[name] = {'AUC': auc, 'Brier': brier}\n",
    "    print(f\"{name:<25} | {auc:.4f}     | {brier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc367ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenyuyue/miniforge3/lib/python3.10/site-packages/arviz/__init__.py:50: FutureWarning: \n",
      "ArviZ is undergoing a major refactor to improve flexibility and extensibility while maintaining a user-friendly interface.\n",
      "Some upcoming changes may be backward incompatible.\n",
      "For details and migration guidance, visit: https://python.arviz.org/en/latest/user_guide/migration_guide.html\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Building Bayesian Hierarchical Model...\n",
      "Formula: is_poor ~ Age + Sex_Code + Race_Code + local_snap_claim_rate + Education_Code + Employment_Status + (1|PUMA)\n",
      "Sampling posterior distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that is_poor==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [Intercept, Age, Sex_Code, Race_Code, local_snap_claim_rate, Education_Code, Employment_Status, 1|PUMA_sigma, 1|PUMA_offset]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cac56c236894d5c974d2a864ff67b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# MCMC Sampling - This may take 5-10 minutes\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling posterior distribution...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 4. View Results\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Bayesian Model Fixed Effects:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bambi/models.py:348\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, include_response_params, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_mean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been replaced by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_response_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not going to work in the future\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m     include_response_params \u001b[38;5;241m=\u001b[39m include_mean\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_response_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bambi/backend/pymc.py:136\u001b[0m, in \u001b[0;36mPyMCModel.run\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_response_params, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# NOTE: Methods return different types of objects (idata, approximation, and dictionary)\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpymc_methods[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbayeux_methods[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m--> 136\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inference_method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpymc_methods[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvi\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    151\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_vi(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bambi/backend/pymc.py:214\u001b[0m, in \u001b[0;36mPyMCModel._run_mcmc\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_response_params, init, n_init, chains, cores, random_seed, sampler_backend, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m         idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvars_to_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValueError: Mass matrix contains\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         ):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pymc/sampling/mcmc.py:928\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m _print_step_hierarchy(step)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 928\u001b[0m     \u001b[43m_mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n\u001b[1;32m    930\u001b[0m     _log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pickle model, sampling singlethreaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pymc/sampling/mcmc.py:1404\u001b[0m, in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, rngs, start, progressbar, progressbar_theme, traces, model, callback, blas_cores, mp_ctx, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sampler:\n\u001b[0;32m-> 1404\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m draw \u001b[38;5;129;01min\u001b[39;00m sampler:\n\u001b[1;32m   1405\u001b[0m             strace \u001b[38;5;241m=\u001b[39m traces[draw\u001b[38;5;241m.\u001b[39mchain]\n\u001b[1;32m   1406\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m zarr_recording:\n\u001b[1;32m   1407\u001b[0m                 \u001b[38;5;66;03m# Zarr recording happens in each process\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pymc/sampling/parallel.py:509\u001b[0m, in \u001b[0;36mParallelSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active:\n\u001b[0;32m--> 509\u001b[0m         draw \u001b[38;5;241m=\u001b[39m \u001b[43mProcessAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_active\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m         proc, is_last, draw, tuning, stats \u001b[38;5;241m=\u001b[39m draw\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    513\u001b[0m             chain_idx\u001b[38;5;241m=\u001b[39mproc\u001b[38;5;241m.\u001b[39mchain, is_last\u001b[38;5;241m=\u001b[39mis_last, draw\u001b[38;5;241m=\u001b[39mdraw, tuning\u001b[38;5;241m=\u001b[39mtuning, stats\u001b[38;5;241m=\u001b[39mstats\n\u001b[1;32m    514\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pymc/sampling/parallel.py:370\u001b[0m, in \u001b[0;36mProcessAdapter.recv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    368\u001b[0m idxs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mid\u001b[39m(proc\u001b[38;5;241m.\u001b[39m_msg_pipe): proc \u001b[38;5;28;01mfor\u001b[39;00m proc \u001b[38;5;129;01min\u001b[39;00m processes}\n\u001b[1;32m    369\u001b[0m proc \u001b[38;5;241m=\u001b[39m idxs[\u001b[38;5;28mid\u001b[39m(ready[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m--> 370\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mready\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     old_error \u001b[38;5;241m=\u001b[39m msg[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/multiprocessing/connection.py:383\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m size:\n\u001b[0;32m--> 383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot end of file during message\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. BAYESIAN HIERARCHICAL MODELING (MrP)\n",
    "import bambi as bmb\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üß† Building Bayesian Hierarchical Model...\")\n",
    "\n",
    "# 1. Take a 10% representative sample (Bayesian MCMC is computationally intense)\n",
    "df_bayes = df.sample(frac=0.1, random_state=42, weights='Person_Weight')\n",
    "\n",
    "# 2. Dynamically build the formula: Target ~ Feat1 + Feat2 + ... + (1|PUMA)\n",
    "# (1|PUMA) tells the model to calculate a specific geographic offset for each PUMA\n",
    "fixed_effects = \" + \".join(features)\n",
    "formula = f\"{target} ~ {fixed_effects} + (1|PUMA)\"\n",
    "\n",
    "print(f\"Formula: {formula}\")\n",
    "\n",
    "# 3. Initialize & Fit Model\n",
    "model = bmb.Model(formula, df_bayes, family=\"bernoulli\")\n",
    "\n",
    "# MCMC Sampling - Added 'cores=1' to prevent the multiprocessing crash\n",
    "print(\"Sampling posterior distribution (Sequentially)...\")\n",
    "results = model.fit(draws=1000, tune=1000, chains=2, cores=1, target_accept=0.9)\n",
    "\n",
    "# 4. View Results\n",
    "print(\"\\nüìä Bayesian Model Fixed Effects:\")\n",
    "print(az.summary(results, var_names=features))\n",
    "\n",
    "# Plot the geographic variances (Random Effects)\n",
    "az.plot_forest(results, var_names=[\"1|PUMA\"], combined=True)\n",
    "plt.title(\"Level-2 Geographic Effects (PUMA Intercepts)\")\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
